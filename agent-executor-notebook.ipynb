{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from IPython.display import display, Markdown, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_md(md):\n",
    "    clear_output()\n",
    "    display(Markdown(md))\n",
    "\n",
    "def display_json(json_data):\n",
    "    display_md(f'```json\\n{json.dumps(json_data, indent=2)}\\n```')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variable if not already set\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROQ_API_KEY is set\n",
      "TAVILY_API_KEY is set\n",
      "LANGCHAIN_API_KEY is set\n",
      "OPENAI_API_KEY is set\n",
      "LANGCHAIN_TRACING_V2 is set\n",
      "LANGCHAIN_ENDPOINT is set\n",
      "LANGCHAIN_PROJECT is set\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# API keys to check\n",
    "api_list = [\"GROQ_API_KEY\", \"TAVILY_API_KEY\", \"LANGCHAIN_API_KEY\", \"OPENAI_API_KEY\", \"LANGCHAIN_TRACING_V2\", \"LANGCHAIN_ENDPOINT\", \"LANGCHAIN_PROJECT\"]\n",
    "\n",
    "# Check if API keys are set\n",
    "for api in api_list:\n",
    "    if os.getenv(api) is None:\n",
    "        print(f\"{api} is not set\")\n",
    "        _set_env(api)\n",
    "    else:\n",
    "        print(f\"{api} is set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the LangChain agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"name\": null,\n",
       "  \"input_variables\": [\n",
       "    \"agent_scratchpad\",\n",
       "    \"input\"\n",
       "  ],\n",
       "  \"optional_variables\": [\n",
       "    \"chat_history\"\n",
       "  ],\n",
       "  \"output_parser\": null,\n",
       "  \"partial_variables\": {\n",
       "    \"chat_history\": []\n",
       "  },\n",
       "  \"metadata\": {\n",
       "    \"lc_hub_owner\": \"hwchase17\",\n",
       "    \"lc_hub_repo\": \"openai-functions-agent\",\n",
       "    \"lc_hub_commit_hash\": \"a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5\"\n",
       "  },\n",
       "  \"tags\": null,\n",
       "  \"messages\": [\n",
       "    {},\n",
       "    {},\n",
       "    {},\n",
       "    {}\n",
       "  ],\n",
       "  \"validate_template\": false,\n",
       "  \"_type\": \"chat\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "display_json(prompt.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the OpenAI Functions agent\n",
    "agent_runnable = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the graph state\n",
    "\n",
    "We now define the graph state. The state for the traditional LangChain agent has a few attributes\n",
    "\n",
    "1. `input`: This is the input string representing the main ask from the user, passed in as input.\n",
    "2. `chat_history`: This is any previous coversation messages, also passed in as input.\n",
    "3. `intermediate_steps`: This is list of actions and corresponding observations that the agent takes over time. This is updated each iteration of the agent.\n",
    "4. `agent_outcome`: This is the response from the agent, either and AgentAction or AgentFinish. the AgentExecutor should finish when this is an AgentFinish, otherwise it should call the requested tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agents-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
